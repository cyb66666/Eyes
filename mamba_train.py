import torch
import torch.nn as nn
import torch.optim as optim
import os
from datetime import datetime
from utils.dataset import loader  # æ•°æ®åŠ è½½
from model.MedMamba import VSSM  # å¯¼å…¥ VSSM æ¨¡åž‹
from tools.focal_loss import FocalLoss
from config import conf
from tools.eval import eval
from tqdm import tqdm

# 1. è®¾å¤‡é€‰æ‹©
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 2. åŠ è½½æ¨¡åž‹
model = VSSM(depths=[2, 2, 4, 2],dims=[96,192,384,768],num_classes=8).to("cuda")
if conf.train.resume:
    model.load_state_dict(torch.load(conf.train.resume))

# 3. æ•°æ®åŠ è½½
train_dataloader = loader(train=True)   # è®­ç»ƒé›†
val_dataloader = loader(train=False)    # éªŒè¯é›†

# 4. å®šä¹‰æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨
criterion = FocalLoss()  # é€‚ç”¨äºŽå¤šåˆ†ç±»ä»»åŠ¡
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # AdamW ä¼˜åŒ–å™¨
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # å­¦ä¹ çŽ‡è°ƒæ•´

# 5. è®­ç»ƒå‚æ•°
num_epochs = 30   # è®­ç»ƒè½®æ•°
best_val_acc = 0  # è®°å½•æœ€ä½³éªŒè¯å‡†ç¡®çŽ‡

# 6. åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤¹
log_dir = "./log"
os.makedirs(log_dir, exist_ok=True)
log_file = os.path.join(log_dir, f"train_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

# 7. è®­ç»ƒå¾ªçŽ¯
with open(log_file, "w") as log:
    log.write("Epoch,Loss,Val_Acc,Macro_Precision,Macro_Recall,Precision_Per_Class,Recall_Per_Class\n")  # å†™å…¥è¡¨å¤´

    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        correct, total = 0, 0

        for images, labels in tqdm(train_dataloader, desc='Traing'):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶
            outputs = model(images)  # å‰å‘ä¼ æ’­
            loss = criterion(outputs, labels)  # è®¡ç®—æŸå¤±
            loss.backward()  # åå‘ä¼ æ’­
            optimizer.step()  # æ›´æ–°å‚æ•°

        scheduler.step()

        # 8. è¯„ä¼°æ¨¡åž‹
        result = eval(model, val_dataloader, criterion)

        log_msg = (
            f"Epoch [{epoch+1}/{num_epochs}] - "
            f"Loss: {result['loss']:.4f} - "
            f"Val Acc: {result['accuracy']:.4f} - "
            f"Macro Precision: {result['macro_precision']:.4f} - "
            f"Macro Recall: {result['macro_recall']:.4f}"
        )
        print(log_msg)
        
        log.write(
            f"{epoch+1},{result['loss']:.4f},{result['accuracy']:.4f},"
            f"{result['macro_precision']:.4f},{result['macro_recall']:.4f},"
            f"{result['precision_per_class']},{result['recall_per_class']}\n"
        )

        # 9. ä¿å­˜æœ€ä½³æ¨¡åž‹
        if result['accuracy'] > best_val_acc:
            best_val_acc = result['accuracy']
            torch.save(model.state_dict(), "./checkpoint/best_vssm_model.pth")
            print("âœ… Best model saved!")
            log.write("âœ… Best model saved!\n")

print("ðŸŽ‰ Training complete!")
